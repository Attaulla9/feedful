{
  "title": "Sony’s new AI driver achieves ‘reliably superhuman’ race times in Gran Turismo",
  "url": "https://www.theverge.com/2022/2/9/22925420/sony-ai-gran-turismo-driving-gt-sophy-nature-paper",
  "date": "2022-02-09T17:30:37.000Z",
  "author": "James Vincent",
  "content": "      <figure>      <img alt=\"FIA Gran Turismo World Tour: Salzburg - Nations Cup\" src=\"https://cdn.vox-cdn.com/thumbor/mzJnc5xQ0JUaWQuTW6OyKPs5q10=/2x0:2987x1990/1310x873/cdn.vox-cdn.com/uploads/chorus_image/image/70488846/1174706815.0.jpg\" />        <figcaption>Photo by Clive Rose - Gran Turismo/Gran Turismo via Getty Images</figcaption>    </figure>  <p id=\"SKtp0D\">AI agents have bested humans at many games, from chess to Go to poker. Now, the machines can claim a new high score on the classic racing video game series <em>Gran Turismo</em>. </p><p id=\"iAwL0V\">Sony announced today that its researchers have developed an AI driver named <a href=\"https://www.gran-turismo.com/us/gran-turismo-sophy/\">GT Sophy</a> that is “reliably superhuman” — able to beat top human drivers in <em>Gran Turismo Sport</em> in back-to-back laps. You might think this an easy challenge. After all, isn’t racing simply a matter of speed and reaction time and therefore simple for a machine to master? But experts in both video game racing and artificial intelligence say GT Sophy’s success is a significant breakthrough, with the agent showing mastery of tactics and strategy.</p><div class=\"c-float-right\"><aside id=\"4OIvA0\"><q>“Outracing human drivers so skilfully [...] represents a landmark achievement for AI”</q></aside></div><p id=\"mLPYC8\">“Outracing human drivers so skilfully in a head-to-head competition represents a landmark achievement for AI,” writes Stanford automotive professor J. Christian Gerdes in <a href=\"https://www.nature.com/articles/d41586-022-00304-2\">an editorial in the scientific journal <em>Nature</em></a> that accompanies <a href=\"https://www.nature.com/articles/s41586-021-04357-7\">a paper describing the work</a>. “GT Sophy’s success on the track suggests that neural networks might one day have a larger role in the software of automated vehicles than they do today.”</p><p id=\"32YCQa\">GT Sophy was trained using a method known as reinforcement learning: essentially a form of trial-and-error in which the AI agent is thrown into an environment with no instructions and rewarded for hitting certain goals. In the case of GT Sophy, Sony’s researchers say they had to craft this “reward function” extremely carefully: for example, fine-tuning penalties for collisions in order to shape a driving style that was aggressive enough to win but that didn’t lead to the AI simply bullying other racers off the road. </p><p id=\"gCm9mf\">Using reinforcement learning, GT Sophy was able to navigate round a racetrack with just a few hours of training and “within a day or two” was faster than 95 percent of drivers in its training dataset. After some 45,000 total hours of training, GT Sophy was able to achieve superhuman performance on three tracks. (For <em>Gran Turismo Sport</em> players, the tracks in question were Dragon Trail Seaside, Lago Maggiore GP, and Circuit de la Sarthe.)</p><p id=\"tjDWR2\">A common concern when testing AI agents against humans is that machines have a number of innate advantages, like perfect recall and fast reaction times. Sony’s researchers note that GT Sophy does have some advantages compared to human players, like a precise map of the course with coordinates of track boundaries and “precise information about the load on each tire, slip angle of each tire, and other vehicle state.” But, they say, they accounted for two particularly important factors: action frequency and reaction time. </p><div id=\"9fDjrR\"><div ><iframe src=\"https://www.youtube.com/embed/l948hMaTPuo?rel=0\"  allowfullscreen=\"\" scrolling=\"no\" allow=\"accelerometer; clipboard-write; encrypted-media; gyroscope; picture-in-picture;\"></iframe></div></div><p id=\"7R4nYm\">GT Sophy’s inputs were capped at 10 Hz, compared to a theoretical maximum human input of 60 Hz. This sometimes led to human drivers displaying “much smoother actions” at high speeds, write the researchers. For reaction times, GT Sophy was able to respond to events in the game environment in 23–30 ms, which is much faster than an estimated top reaction time for professional athletes of 200–250 ms. To compensate, researchers added artificial delay, training GT Sophy with reaction times of 100 ms, 200 ms, and 250 ms. But as they found out: “All three of these tests achieved a superhuman lap time.”</p><p id=\"mKZOrx\">GT Sophy was tested against a trio of top e-sport drivers: Emily Jones, Valerio Gallo, and Igor Fraga. Although none of the humans were able to beat the AI in time trials, their match-ups lead to them discovering new tactics. </p><p id=\"xysCgU\">“It was really interesting seeing the lines where the AI would go, there were certain corners where I was going out wide and then cutting back in, and the AI was going in all the way around, so I learned a lot about the lines,” e-sports driver Emily Jones said in a testimonial in the <em>Nature </em>paper. “Going into turn 1, for example, I was braking later than the AI, but the AI would get a much better exit than me and beat me to the next corner. I didn’t notice that until I saw the AI and was like, ‘Okay, I should do that instead.’”</p><p id=\"OOoudl\">Sony says it’s currently working on integrating GT Sophy into future <em>Gran Turismo</em> titles but didn’t offer a schedule for when this might happen. </p>",
  "image": "https://cdn.vox-cdn.com/thumbor/ZS23-CCqWU0ayo6R-ivNH4qenBI=/0x213:2988x1777/fit-in/1200x630/cdn.vox-cdn.com/uploads/chorus_asset/file/23229622/1174706815.jpg",
  "description": "AI outraces humans in Gran Turismo.",
  "publisher": "The Verge",
  "publisherUrl": "https://www.theverge.com/"
}